version: '3'

# Experiments - Scenario lifecycle tasks
#
# Scenarios use components and run on:
# - Kind: Local Kind clusters
# - Talos: Talos Linux clusters (future)
# - Cloud: AKS/EKS clusters via GitLab CI (future)

silent: true

vars:
  ORCHESTRATOR_CLUSTER: orchestrator
  ARGOCD_NAMESPACE: argocd
  # Container names for local infrastructure
  CPK_CONTAINER: cloud-provider-kind
  DNSMASQ_CONTAINER: kind-dnsmasq
  DNSMASQ_DOMAIN: k8s.local

tasks:
  # =============================================================================
  # Internal Helpers - Docker-based infrastructure for Kind
  # =============================================================================
  _ensure-cloud-provider-kind:
    internal: true
    cmds:
      - |
        # Check if already running
        if docker ps --format '{{.Names}}' | grep -q "^{{.CPK_CONTAINER}}$"; then
          echo "  [cloud-provider-kind] Already running"
          exit 0
        fi

        # Remove any stopped container with same name
        docker rm -f {{.CPK_CONTAINER}} 2>/dev/null || true

        echo "  [cloud-provider-kind] Starting container..."
        docker run -d \
          --name {{.CPK_CONTAINER}} \
          --network kind \
          --restart unless-stopped \
          -v /var/run/docker.sock:/var/run/docker.sock \
          registry.k8s.io/cloud-provider-kind/cloud-controller-manager:v0.6.0

        sleep 2

        if docker ps --format '{{.Names}}' | grep -q "^{{.CPK_CONTAINER}}$"; then
          echo "  [cloud-provider-kind] Running"
        else
          echo "  [cloud-provider-kind] Failed to start"
          docker logs {{.CPK_CONTAINER}} 2>&1 | tail -10
          exit 1
        fi

  _ensure-dnsmasq:
    internal: true
    cmds:
      - |
        # Check if already running
        if docker ps --format '{{.Names}}' | grep -q "^{{.DNSMASQ_CONTAINER}}$"; then
          echo "  [dnsmasq] Already running"
          exit 0
        fi

        # Remove any stopped container with same name
        docker rm -f {{.DNSMASQ_CONTAINER}} 2>/dev/null || true

        echo "  [dnsmasq] Starting container..."

        # Create dnsmasq config
        mkdir -p /tmp/kind-dnsmasq
        cat > /tmp/kind-dnsmasq/dnsmasq.conf << 'EOF'
        # Kind cluster DNS
        # Resolves *.k8s.local to the kind Docker network
        no-resolv
        no-hosts
        # Forward other queries to Google DNS
        server=8.8.8.8
        server=8.8.4.4
        # Wildcard for k8s.local - updated dynamically
        address=/k8s.local/127.0.0.1
        EOF

        docker run -d \
          --name {{.DNSMASQ_CONTAINER}} \
          --network kind \
          --restart unless-stopped \
          --cap-add NET_ADMIN \
          -p 127.0.0.1:5353:53/udp \
          -v /tmp/kind-dnsmasq:/etc/dnsmasq.d:ro \
          andyshinn/dnsmasq:latest \
          --conf-dir=/etc/dnsmasq.d,*.conf --no-daemon --log-facility=-

        sleep 2

        if docker ps --format '{{.Names}}' | grep -q "^{{.DNSMASQ_CONTAINER}}$"; then
          echo "  [dnsmasq] Running on 127.0.0.1:5353"
          echo "  [dnsmasq] Test with: dig @127.0.0.1 -p 5353 test.{{.DNSMASQ_DOMAIN}}"
        else
          echo "  [dnsmasq] Failed to start"
          docker logs {{.DNSMASQ_CONTAINER}} 2>&1 | tail -10
          exit 1
        fi

  _update-dns:
    internal: true
    cmds:
      - |
        # Skip if dnsmasq container not running
        if ! docker ps --format '{{.Names}}' | grep -q "^{{.DNSMASQ_CONTAINER}}$"; then
          exit 0
        fi

        echo "  [dnsmasq] Updating DNS entries..."

        # Rebuild config with current LoadBalancer IPs
        mkdir -p /tmp/kind-dnsmasq
        cat > /tmp/kind-dnsmasq/dnsmasq.conf << 'EOF'
        no-resolv
        no-hosts
        server=8.8.8.8
        server=8.8.4.4
        EOF

        # Add entries for all LoadBalancer services
        for cluster in $(kind get clusters 2>/dev/null); do
          kubectl --context "kind-${cluster}" get svc -A -o json 2>/dev/null | \
            jq -r '.items[] | select(.spec.type=="LoadBalancer") | select(.status.loadBalancer.ingress != null) | "address=/\(.metadata.name).\(.metadata.namespace).{{.DNSMASQ_DOMAIN}}/\(.status.loadBalancer.ingress[0].ip)"' \
            >> /tmp/kind-dnsmasq/dnsmasq.conf
        done

        # Restart dnsmasq to pick up changes
        docker restart {{.DNSMASQ_CONTAINER}} > /dev/null
        echo "  [dnsmasq] Updated"

  _stop-infrastructure:
    internal: true
    cmds:
      - |
        echo "Stopping local infrastructure containers..."
        docker rm -f {{.CPK_CONTAINER}} 2>/dev/null && echo "  Stopped {{.CPK_CONTAINER}}" || true
        docker rm -f {{.DNSMASQ_CONTAINER}} 2>/dev/null && echo "  Stopped {{.DNSMASQ_CONTAINER}}" || true
        rm -rf /tmp/kind-dnsmasq 2>/dev/null || true

  # =============================================================================
  # Listing
  # =============================================================================
  list:
    desc: List available experiments
    cmds:
      - tree experiments/scenarios -L 1 -d --noreport 2>/dev/null || ls -d experiments/scenarios/*/

  # =============================================================================
  # Kind Experiment Lifecycle
  # =============================================================================
  kind:conduct:
    desc: "Conduct experiment on Kind: task experiments:kind:conduct -- <experiment-name>"
    cmds:
      - task: _ensure-cloud-provider-kind
      - task: _ensure-dnsmasq
      - |
        if [ -z "{{.CLI_ARGS}}" ]; then
          echo "Usage: task experiments:kind:conduct -- <experiment-name> [USERS=10] [DURATION=60s]"
          exit 1
        fi

        EXP_NAME="{{.CLI_ARGS}}"
        EXP_PATH="experiments/scenarios/$EXP_NAME"
        WORKFLOW_FILE="$EXP_PATH/workflow/experiment.yaml"

        if [ ! -d "$EXP_PATH" ]; then
          echo "ERROR: Experiment not found at $EXP_PATH"
          exit 1
        fi

        if [ ! -f "$WORKFLOW_FILE" ]; then
          echo "ERROR: Workflow not found at $WORKFLOW_FILE"
          exit 1
        fi

        USERS={{.USERS | default "10"}}
        DURATION={{.DURATION | default "60s"}}

        echo "=============================================="
        echo "  CONDUCTING EXPERIMENT: $EXP_NAME"
        echo "=============================================="
        echo "  Users: $USERS"
        echo "  Duration: $DURATION"
        echo ""

        # Step 1: Discover clusters from experiment folders
        echo "=== Step 1/5: Discovering clusters ==="
        CLUSTERS=""
        for cluster_dir in "$EXP_PATH"/*/; do
          if [ -f "$cluster_dir/cluster.yaml" ]; then
            cluster_name=$(basename "$cluster_dir")
            CLUSTERS="$CLUSTERS $cluster_name"
            echo "  Found: $cluster_name"
          fi
        done

        if [ -z "$CLUSTERS" ]; then
          echo "ERROR: No clusters found (no */cluster.yaml files)"
          exit 1
        fi

        # Step 2: Create kind clusters for experiment
        echo ""
        echo "=== Step 2/5: Creating experiment clusters ==="
        for cluster in $CLUSTERS; do
          full_name="${EXP_NAME}-${cluster}"
          if kind get clusters 2>/dev/null | grep -q "^${full_name}$"; then
            echo "  Cluster '$full_name' already exists"
          else
            echo "  Creating cluster '$full_name'..."
            kind create cluster --name "$full_name" --wait 60s
          fi
        done

        # Step 3: Register clusters with ArgoCD on orchestrator
        echo ""
        echo "=== Step 3/5: Registering clusters with ArgoCD ==="
        for cluster in $CLUSTERS; do
          full_name="${EXP_NAME}-${cluster}"
          echo "  Registering: $full_name"

          # Get the cluster's internal Docker IP (for cross-cluster communication)
          CLUSTER_CONTEXT="kind-${full_name}"
          CONTAINER_NAME="${full_name}-control-plane"
          CLUSTER_IP=$(docker inspect "$CONTAINER_NAME" | jq -r '.[0].NetworkSettings.Networks.kind.IPAddress')
          CLUSTER_SERVER="https://${CLUSTER_IP}:6443"
          CLUSTER_CA=$(kubectl config view --raw -o jsonpath="{.clusters[?(@.name=='${CLUSTER_CONTEXT}')].cluster.certificate-authority-data}")

          # Create service account on target cluster for ArgoCD
          kubectl --context "$CLUSTER_CONTEXT" create serviceaccount argocd-manager -n kube-system 2>/dev/null || true
          kubectl --context "$CLUSTER_CONTEXT" create clusterrolebinding argocd-manager --clusterrole=cluster-admin --serviceaccount=kube-system:argocd-manager 2>/dev/null || true

          # Create SA token secret
          cat > /tmp/sa-token.yaml << 'ENDOFFILE'
        apiVersion: v1
        kind: Secret
        metadata:
          name: argocd-manager-token
          namespace: kube-system
          annotations:
            kubernetes.io/service-account.name: argocd-manager
        type: kubernetes.io/service-account-token
        ENDOFFILE
          kubectl --context "$CLUSTER_CONTEXT" apply -f /tmp/sa-token.yaml
          sleep 2
          TOKEN=$(kubectl --context "$CLUSTER_CONTEXT" -n kube-system get secret argocd-manager-token -o jsonpath='{.data.token}' | base64 -d)

          # Register with ArgoCD on orchestrator
          cat > /tmp/cluster-secret.yaml << ENDOFFILE
        apiVersion: v1
        kind: Secret
        metadata:
          name: cluster-${cluster}
          namespace: argocd
          labels:
            argocd.argoproj.io/secret-type: cluster
        type: Opaque
        stringData:
          name: "${cluster}"
          server: "${CLUSTER_SERVER}"
          config: |
            {
              "bearerToken": "${TOKEN}",
              "tlsClientConfig": {
                "insecure": true
              }
            }
        ENDOFFILE
          kubectl --context kind-{{.ORCHESTRATOR_CLUSTER}} apply -f /tmp/cluster-secret.yaml
          echo "    Registered: $cluster -> $CLUSTER_SERVER"
        done

        # Step 4: Deploy ArgoCD apps from orchestrator to experiment clusters
        echo ""
        echo "=== Step 4/5: Deploying apps via ArgoCD ==="
        for cluster in $CLUSTERS; do
          full_name="${EXP_NAME}-${cluster}"
          cluster_dir="$EXP_PATH/$cluster"
          argocd_dir="$cluster_dir/argocd"

          # Apply ArgoCD Application manifests to orchestrator (they sync the rest)
          if [ -d "$argocd_dir" ] && [ -f "$argocd_dir/app.yaml" ]; then
            echo "  Applying to orchestrator: app.yaml -> $full_name"
            kubectl --context kind-{{.ORCHESTRATOR_CLUSTER}} apply -f "$argocd_dir/app.yaml"
          fi
        done

        # Wait for ArgoCD to sync
        echo "  Waiting for sync..."
        sleep 15
      - task: _update-dns
      - |
        EXP_NAME="{{.CLI_ARGS}}"
        EXP_PATH="experiments/scenarios/$EXP_NAME"
        WORKFLOW_FILE="$EXP_PATH/workflow/experiment.yaml"

        # Step 5: Run workflow on orchestrator
        echo ""
        echo "=== Step 5/6: Running workflow on orchestrator ==="
        kubectl config use-context kind-{{.ORCHESTRATOR_CLUSTER}}

        # Determine target URL (target cluster's Docker IP + NodePort)
        TARGET_CONTAINER="${EXP_NAME}-target-control-plane"
        TARGET_IP=$(docker inspect "$TARGET_CONTAINER" | jq -r '.[0].NetworkSettings.Networks.kind.IPAddress')
        TARGET_URL="http://${TARGET_IP}:30080"
        echo "  Target URL: $TARGET_URL"

        USERS={{.USERS | default "10"}}
        DURATION={{.DURATION | default "60s"}}

        WORKFLOW_NAME=$(argo submit "$WORKFLOW_FILE" \
          -p users="$USERS" \
          -p duration="$DURATION" \
          -p target-url="$TARGET_URL" \
          -o name -n argo-workflows 2>/dev/null || \
          kubectl create -f "$WORKFLOW_FILE" -o name)
        echo "  Workflow: $WORKFLOW_NAME"

        echo "  Waiting for workflow completion..."
        argo wait "$WORKFLOW_NAME" -n argo-workflows 2>/dev/null || \
          kubectl wait "$WORKFLOW_NAME" --for=condition=Completed --timeout=30m -n argo-workflows

        echo ""
        echo "=== Workflow Results ==="
        argo get "$WORKFLOW_NAME" -n argo-workflows 2>/dev/null || \
          kubectl get "$WORKFLOW_NAME" -n argo-workflows -o yaml

        # Step 6: Cleanup experiment clusters
        echo ""
        echo "=== Step 6/6: Cleaning up experiment clusters ==="
        for cluster_dir in "$EXP_PATH"/*/; do
          if [ -f "$cluster_dir/cluster.yaml" ]; then
            cluster=$(basename "$cluster_dir")
            full_name="${EXP_NAME}-${cluster}"
            echo "  Deleting cluster: $full_name"
            kind delete cluster --name "$full_name"
          fi
        done

        kubectl config use-context kind-{{.ORCHESTRATOR_CLUSTER}}

        echo ""
        echo "=============================================="
        echo "  EXPERIMENT COMPLETE"
        echo "=============================================="

  kind:destroy:
    desc: "Destroy Kind experiment clusters: task experiments:kind:destroy -- <experiment-name>"
    cmds:
      - |
        if [ -z "{{.CLI_ARGS}}" ]; then
          echo "Usage: task experiments:kind:destroy -- <experiment-name>"
          echo ""
          echo "Example: task experiments:kind:destroy -- http-baseline"
          exit 1
        fi

        EXP_NAME="{{.CLI_ARGS}}"
        EXP_PATH="experiments/scenarios/$EXP_NAME"

        if [ ! -d "$EXP_PATH" ]; then
          echo "ERROR: Experiment not found at $EXP_PATH"
          exit 1
        fi

        echo "Destroying experiment clusters for: $EXP_NAME"
        for cluster_dir in "$EXP_PATH"/*/; do
          if [ -f "$cluster_dir/cluster.yaml" ]; then
            cluster_name=$(basename "$cluster_dir")
            full_name="${EXP_NAME}-${cluster_name}"
            if kind get clusters 2>/dev/null | grep -q "^${full_name}$"; then
              echo "  Deleting: $full_name"
              kind delete cluster --name "$full_name"
            fi
          fi
        done

        echo "Done."

  # =============================================================================
  # Cloud Experiment Lifecycle
  # =============================================================================
  cloud:conduct:
    desc: "Conduct experiment on cloud: task experiments:cloud:conduct -- <experiment-name>"
    cmds:
      - |
        if [ -z "{{.CLI_ARGS}}" ]; then
          echo "Usage: task experiments:cloud:conduct -- <experiment-name> [USERS=10] [DURATION=60s]"
          exit 1
        fi

        EXP_NAME="{{.CLI_ARGS}}"
        EXP_PATH="experiments/scenarios/$EXP_NAME"

        echo "=============================================="
        echo "  CONDUCTING CLOUD EXPERIMENT: $EXP_NAME"
        echo "=============================================="
        echo ""

        # Step 1: Discover clusters from experiment folders
        echo "=== Step 1/6: Discovering clusters ==="
        CLUSTERS=""
        for cluster_dir in "$EXP_PATH"/*/; do
          if [ -f "$cluster_dir/cluster.yaml" ]; then
            cluster_name=$(basename "$cluster_dir")
            CLUSTERS="$CLUSTERS $cluster_name"
            echo "  Found: $cluster_name"
          fi
        done

        # Step 2: Trigger GitLab CI to provision clusters
        echo ""
        echo "=== Step 2/6: Provisioning cloud clusters via GitLab CI ==="
        echo "TODO: Implement GitLab CI integration"
        echo "  - Read cluster.yaml for each cluster"
        echo "  - Trigger GitLab CI pipeline for each"
        echo "  - Wait for clusters to be ready"
        echo "  - Retrieve kubeconfigs"
        exit 1

        # Step 3: Register clusters with ArgoCD on orchestrator
        echo ""
        echo "=== Step 3/6: Registering clusters with ArgoCD ==="
        echo "TODO: argocd cluster add for each cluster"

        # Step 4: Deploy apps via ArgoCD
        echo ""
        echo "=== Step 4/6: Deploying apps to clusters ==="
        echo "TODO: Apply ArgoCD apps for each cluster"

        # Step 5: Run workflow on orchestrator
        echo ""
        echo "=== Step 5/6: Running workflow ==="
        echo "TODO: Submit workflow with cloud target URLs"

        # Step 6: Cleanup - destroy cloud clusters
        echo ""
        echo "=== Step 6/6: Destroying cloud clusters ==="
        echo "TODO: Trigger GitLab CI destroy pipeline"

  cloud:deploy:
    desc: "Deploy experiment to cloud (without running): task experiments:cloud:deploy -- <experiment-name>"
    cmds:
      - |
        if [ -z "{{.CLI_ARGS}}" ]; then
          echo "Usage: task experiments:cloud:deploy -- <experiment-name>"
          exit 1
        fi

        EXP_NAME="{{.CLI_ARGS}}"
        EXP_PATH="experiments/scenarios/$EXP_NAME"

        echo "Deploying cloud experiment: $EXP_NAME"
        echo ""
        echo "TODO: Implement GitLab CI provisioning"
        echo "  1. Parse cluster.yaml files"
        echo "  2. Trigger GitLab CI pipelines"
        echo "  3. Wait for clusters"
        echo "  4. Register with ArgoCD"
        echo "  5. Deploy apps"

  cloud:destroy:
    desc: "Destroy cloud experiment clusters: task experiments:cloud:destroy -- <experiment-name>"
    cmds:
      - |
        if [ -z "{{.CLI_ARGS}}" ]; then
          echo "Usage: task experiments:cloud:destroy -- <experiment-name>"
          exit 1
        fi

        EXP_NAME="{{.CLI_ARGS}}"
        EXP_PATH="experiments/scenarios/$EXP_NAME"

        echo "Destroying cloud experiment: $EXP_NAME"
        echo ""
        echo "TODO: Implement GitLab CI destroy"
        echo "  1. Trigger GitLab CI destroy pipeline for each cluster"
        echo "  2. Remove from ArgoCD"
