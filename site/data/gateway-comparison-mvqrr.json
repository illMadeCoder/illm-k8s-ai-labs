{
  "name": "gateway-comparison-mvqrr",
  "namespace": "experiments",
  "description": "Gateway comparison - NGINX Ingress vs Traefik vs Envoy Gateway feature and performance analysis",
  "createdAt": "2026-02-12T19:32:08Z",
  "completedAt": "2026-02-12T20:09:09.24130383Z",
  "durationSeconds": 2221.24130383,
  "phase": "Complete",
  "tags": [
    "comparison",
    "networking",
    "gateway"
  ],
  "study": {
    "hypothesis": "Envoy Gateway will have the richest feature set because it implements Gateway API natively with Envoy's extensible filter chain architecture, but this comes at higher base resource usage because it runs a separate control plane and data plane process, while NGINX Ingress will be the most resource-efficient for simple routing because its single-process model avoids the overhead of a dedicated control plane",
    "questions": [
      "What is the idle and loaded CPU/memory footprint of each gateway controller?",
      "Which gateways support Gateway API natively vs. requiring translation layers?",
      "How do configuration models compare (Ingress vs. Gateway API vs. custom CRDs)?"
    ],
    "focus": [
      "resource efficiency",
      "Gateway API conformance",
      "configuration complexity",
      "feature breadth"
    ]
  },
  "analysisConfig": {
    "sections": [
      "abstract",
      "targetAnalysis",
      "performanceAnalysis",
      "metricInsights",
      "finopsAnalysis",
      "secopsAnalysis",
      "body",
      "capabilitiesMatrix",
      "feedback",
      "architectureDiagram"
    ]
  },
  "targets": [
    {
      "name": "app",
      "clusterName": "gateway-comparison-mvqrr-app",
      "clusterType": "gke",
      "machineType": "e2-standard-4",
      "nodeCount": 1
    }
  ],
  "workflow": {
    "name": "gateway-comparison-mvqrr-validation",
    "template": "gateway-comparison-validation",
    "phase": "Succeeded",
    "startedAt": "2026-02-12T19:48:37Z",
    "finishedAt": "2026-02-12T20:09:00Z"
  },
  "metrics": {
    "collectedAt": "2026-02-12T20:09:09.443618492Z",
    "source": "target:cadvisor",
    "timeRange": {
      "start": "2026-02-12T19:32:08Z",
      "end": "2026-02-12T20:09:09.443618492Z",
      "duration": "37m1.443618492s",
      "stepSeconds": 0
    },
    "queries": {
      "cpu_by_pod": {
        "query": "container_cpu_usage_seconds_total by pod (cadvisor)",
        "type": "instant",
        "unit": "cores",
        "description": "CPU usage by pod (cumulative seconds)",
        "data": [
          {
            "labels": {
              "pod": "kube-state-metrics-0"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 2.618468
          },
          {
            "labels": {
              "pod": "operator-64d66c8747-x94st"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 3.290369
          },
          {
            "labels": {
              "pod": "ts-vm-hub-xmccv-0"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 1.521588
          },
          {
            "labels": {
              "pod": "traefik-6799d8789c-n6v52"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 2.069895
          },
          {
            "labels": {
              "pod": "alloy-kzv7j"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 7.635426
          },
          {
            "labels": {
              "pod": "ingress-nginx-controller-766749c598-8lw8q"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 2.39952
          },
          {
            "labels": {
              "pod": "envoy-gateway-56646c568b-wxcbw"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 3.735217
          }
        ]
      },
      "cpu_total": {
        "query": "sum(container_cpu_usage_seconds_total) (cadvisor)",
        "type": "instant",
        "unit": "cores",
        "description": "Total CPU usage (cumulative seconds)",
        "data": [
          {
            "labels": {
              "scope": "total"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 23.270482999999995
          }
        ]
      },
      "memory_by_pod": {
        "query": "container_memory_working_set_bytes by pod (cadvisor)",
        "type": "instant",
        "unit": "bytes",
        "description": "Memory working set by pod",
        "data": [
          {
            "labels": {
              "pod": "alloy-kzv7j"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 42790912
          },
          {
            "labels": {
              "pod": "ingress-nginx-controller-766749c598-8lw8q"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 30429184
          },
          {
            "labels": {
              "pod": "envoy-gateway-56646c568b-wxcbw"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 35627008
          },
          {
            "labels": {
              "pod": "kube-state-metrics-0"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 38670336
          },
          {
            "labels": {
              "pod": "operator-64d66c8747-x94st"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 26898432
          },
          {
            "labels": {
              "pod": "ts-vm-hub-xmccv-0"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 25812992
          },
          {
            "labels": {
              "pod": "traefik-6799d8789c-n6v52"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 28925952
          }
        ]
      },
      "memory_total": {
        "query": "sum(container_memory_working_set_bytes) (cadvisor)",
        "type": "instant",
        "unit": "bytes",
        "description": "Total memory working set",
        "data": [
          {
            "labels": {
              "scope": "total"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 229154816
          }
        ]
      }
    }
  },
  "costEstimate": {
    "totalUSD": 0.016535907484067778,
    "durationHours": 0.6170114732861111,
    "perTarget": {
      "app": 0.016535907484067778
    },
    "note": "Rough estimate based on on-demand GCE pricing; actual cost may differ."
  },
  "analysis": {
    "finopsAnalysis": {
      "overview": "This 37-minute gateway comparison experiment ran on a single e2-standard-4 GKE node and cost approximately $0.0165 USD. The cost is minimal because it was a short-duration benchmark, but the single-node topology and use of e2-standard-4 (4 vCPU, 16 GB RAM) means most of the node's capacity was idle — total memory working set across all pods was only ~218 MiB out of 16 GB available, and cumulative CPU usage of ~23.3 core-seconds over 37 minutes translates to roughly 0.010 cores average utilization on a 4-core node (0.26% utilization).",
      "costDrivers": [
        "GKE node compute is the sole cost driver at $0.0165 for 0.617 hours of an e2-standard-4 instance ($0.134/hr on-demand). All three gateway controllers plus observability stack (Alloy, kube-state-metrics, operator, Tailscale hub) fit on a single node, meaning the minimum billable unit is one full VM regardless of actual utilization.",
        "Observability and platform overhead pods (Alloy at 7.6 core-seconds CPU and 42.8 MiB memory, kube-state-metrics at 2.6 core-seconds and 36.9 MiB, operator at 3.3 core-seconds and 25.6 MiB) collectively consumed more resources than any individual gateway controller, accounting for ~58% of total CPU and ~47% of total memory."
      ],
      "projection": "For production 24/7 operation, each gateway would run on its own cluster or node pool with redundancy. A realistic multi-node production setup per gateway: 3-node cluster with e2-standard-4 nodes (for HA across zones) at $0.134/hr per node. Monthly cost per gateway cluster: 3 nodes × $0.134/hr × 730 hrs/month = $293.46/month. Running all three gateways in separate production clusters: $293.46 × 3 = $880.38/month. However, Envoy Gateway requires additional data-plane proxy pods (envoy-default-* pods not captured in this experiment) which would increase its node resource consumption — realistically requiring e2-standard-8 nodes or an additional node, pushing its cluster to ~$390-$587/month. Using committed-use discounts (1-year CUD: 37% discount) reduces total to ~$554-$620/month for all three. If consolidating to a single production cluster with 3× e2-standard-8 nodes: 3 × $0.268/hr × 730 = $586.92/month. Note: actual production costs will also include load balancer IPs ($18.26/month each in GCP), persistent disks, and egress — likely adding $50-100/month per cluster.",
      "optimizations": [
        "Right-size the experiment node: an e2-medium (2 vCPU, 4 GB) at $0.034/hr would suffice for this idle/light-load benchmark, reducing experiment cost by ~75% to ~$0.004 per run.",
        "Use preemptible/spot VMs for benchmarking: e2-standard-4 spot pricing is ~$0.040/hr (70% savings), reducing this experiment to ~$0.005.",
        "Consolidate observability: Alloy alone consumed 33% of total CPU — consider sampling or reducing collection frequency during short benchmarks. Alternatively, use a shared external observability stack rather than deploying per-experiment.",
        "For production, Envoy Gateway's two-process architecture (control plane + data plane) means its total resource envelope is larger than measured here. Size node pools based on the combined footprint, not just the control-plane pod metrics captured in this experiment."
      ]
    },
    "secopsAnalysis": {
      "overview": "The experiment deploys three ingress/gateway controllers alongside observability and connectivity components on a single GKE node. The single-node, short-lived nature limits blast radius, but several security considerations apply to any production adoption of these components. No network policies, RBAC restrictions, or pod security standards are evident in the experiment data — all pods appear to run in default configurations.",
      "findings": [
        "RBAC over-provisioning risk: NGINX Ingress Controller, Traefik, and Envoy Gateway all require cluster-wide RBAC permissions to watch Ingress/Gateway API resources across namespaces. In production, each controller's ClusterRole should be audited and scoped to the minimum required API groups and verbs. Running all three simultaneously means three separate service accounts with broad read access to cluster routing configuration, increasing the credential attack surface.",
        "No network policy segmentation observed: All gateway controllers, the operator, Alloy telemetry agent, kube-state-metrics, and the Tailscale VPN hub (ts-vm-hub) run on the same node with no apparent NetworkPolicy enforcement. In production, each gateway's control plane should be isolated via NetworkPolicies restricting ingress/egress to only required endpoints (API server, data-plane pods, webhook endpoints). The Tailscale hub pod is particularly sensitive — it provides network connectivity and should be tightly restricted.",
        "Tailscale VPN hub (ts-vm-hub) is present in the workload, providing remote access to the cluster. This is a high-privilege connectivity component: if compromised, it could provide network-level access to the cluster. Its credentials and auth keys should be rotated regularly, and its pod should run with a restrictive SecurityContext (read-only root filesystem, non-root UID, dropped capabilities).",
        "No resource limits or requests are evident in the metrics data. Without resource limits, a compromised or misbehaving gateway pod could consume all node resources, causing denial of service to other pods. All three gateways and the observability stack should have CPU/memory limits set, especially in a shared-node topology.",
        "The NGINX Ingress Controller runs an embedded Lua interpreter for dynamic configuration, which expands the attack surface compared to static-config proxies. Ensure the controller version is patched against known Lua sandbox escapes and NGINX CVEs. Traefik and Envoy Gateway should similarly be pinned to versions with no known critical CVEs."
      ],
      "supplyChain": "Image provenance is not verifiable from the experiment data alone. NGINX Ingress Controller images are published by the Kubernetes project (registry.k8s.io/ingress-nginx) and have cosign signatures available but SBOM adoption is partial. Traefik publishes official images on Docker Hub (traefik) with no cosign signatures or SBOM attestations in their standard distribution as of early 2025. Envoy Gateway images are published by the Envoy project (docker.io/envoyproxy) and have begun adopting cosign-signed images with SLSA provenance, though completeness varies by release. For production, all three should be verified against cosign signatures where available, images should be pulled from a private registry mirror with admission control (e.g., Kyverno or OPA Gatekeeper policy requiring signature verification), and SBOM attestations should be required to track transitive dependency vulnerabilities — particularly important for NGINX (C/Lua) and Envoy (C++) which have native code dependencies not visible in container layer scanning alone."
    },
    "capabilitiesMatrix": {
      "technologies": [
        "NGINX Ingress",
        "Traefik",
        "Envoy Gateway"
      ],
      "categories": [
        {
          "name": "Resource Efficiency",
          "capabilities": [
            {
              "name": "CPU usage (avg cores over 37 min)",
              "values": {
                "NGINX Ingress": "~0.001 cores (2.4 core-sec / 2221s)",
                "Traefik": "~0.0009 cores (2.1 core-sec / 2221s)",
                "Envoy Gateway": "~0.0017 cores (3.7 core-sec / 2221s) — control plane only"
              }
            },
            {
              "name": "Memory working set",
              "values": {
                "NGINX Ingress": "~29 MiB",
                "Traefik": "~27.6 MiB",
                "Envoy Gateway": "~34 MiB — control plane only, data-plane pods not captured"
              }
            },
            {
              "name": "Architectural overhead",
              "values": {
                "NGINX Ingress": "Single-process (NGINX + Lua controller in one pod)",
                "Traefik": "Single Go binary (control + data plane combined)",
                "Envoy Gateway": "Two-process (controller pod + separate Envoy proxy pods); total footprint undercounted here"
              }
            }
          ]
        },
        {
          "name": "Gateway API Support",
          "capabilities": [
            {
              "name": "Native Gateway API implementation",
              "values": {
                "NGINX Ingress": "Add-on translation layer; not native",
                "Traefik": "Experimental provider; partial native support",
                "Envoy Gateway": "Reference implementation; fully native"
              }
            },
            {
              "name": "Conformance level",
              "values": {
                "NGINX Ingress": "Core (via translation); limited Extended support",
                "Traefik": "Core + some Extended; Experimental features gated",
                "Envoy Gateway": "Core + Extended; broadest Experimental coverage"
              }
            }
          ]
        },
        {
          "name": "Configuration Model",
          "capabilities": [
            {
              "name": "Primary API surface",
              "values": {
                "NGINX Ingress": "Ingress resources + annotations; Gateway API via separate CRDs",
                "Traefik": "Ingress, IngressRoute CRDs, and Gateway API (three models)",
                "Envoy Gateway": "Gateway API exclusively (HTTPRoute, GRPCRoute, etc.)"
              }
            },
            {
              "name": "Complexity for simple routing",
              "values": {
                "NGINX Ingress": "Low — familiar Ingress annotations",
                "Traefik": "Low to moderate — multiple overlapping APIs",
                "Envoy Gateway": "Moderate — Gateway API is more verbose but more expressive"
              }
            },
            {
              "name": "Advanced configuration ergonomics",
              "values": {
                "NGINX Ingress": "Annotation sprawl; snippets needed for non-standard features",
                "Traefik": "Clean via IngressRoute CRDs and middleware chains",
                "Envoy Gateway": "Structured via BackendTrafficPolicy, SecurityPolicy, and EnvoyPatchPolicy CRDs"
              }
            }
          ]
        },
        {
          "name": "Extensibility and Feature Breadth",
          "capabilities": [
            {
              "name": "Filter / middleware architecture",
              "values": {
                "NGINX Ingress": "Limited — Lua plugins and NGINX snippets; no formal chain",
                "Traefik": "Built-in middleware chain (rate-limit, circuit-breaker, headers, etc.)",
                "Envoy Gateway": "Full Envoy filter chain (Wasm, ext_proc, Lua, ext_authz); richest extensibility"
              }
            },
            {
              "name": "Protocol support beyond HTTP",
              "values": {
                "NGINX Ingress": "TCP/UDP via ConfigMap; gRPC supported",
                "Traefik": "TCP, UDP, gRPC natively via IngressRoute",
                "Envoy Gateway": "TCP, UDP, gRPC, HTTP/3 via Gateway API route types"
              }
            }
          ]
        }
      ],
      "summary": "Traefik wins on resource efficiency for simple routing, narrowly beating NGINX Ingress on both CPU and memory while offering a cleaner advanced-config model. Envoy Gateway is the clear winner for Gateway API conformance and extensibility, but its two-process architecture imposes measurably higher overhead—and the true cost is undercounted here because the Envoy data-plane proxy pods were not captured in metrics. The key trade-off is operational simplicity and lower resource cost (Traefik or NGINX) versus future-proof Gateway API nativeness and filter-chain extensibility (Envoy Gateway)."
    },
    "feedback": {
      "recommendations": [
        "Capture Envoy data-plane proxy pods (envoy-default-*) in metrics collection to measure Envoy Gateway's true total resource footprint; the current data only reflects the control plane.",
        "Add a load-generation phase (e.g., hey or k6) with defined RPS targets to compare latency percentiles and throughput under realistic traffic, since idle-only metrics do not differentiate proxy performance.",
        "Test Gateway API conformance explicitly by deploying a standard conformance test suite (gateway-api/conformance) against each implementation to quantify Core/Extended/Experimental support gaps with concrete pass/fail data.",
        "Include Traefik's IngressRoute and NGINX's annotation-based routing alongside Gateway API HTTPRoute to compare equivalent routing configurations across all three native config models."
      ],
      "experimentDesign": [
        "Separate the experiment into distinct idle and loaded phases with clear boundaries, collecting time-series data (not just cumulative counters) to enable per-phase CPU rate and memory trend analysis rather than relying on single-point-in-time snapshots.",
        "Add application-level metrics (request latency p50/p95/p99, error rates, connection setup time) via a sidecar or test client to measure actual proxy performance beyond infrastructure resource consumption.",
        "Run the experiment for a longer duration (15-30 minutes per phase minimum) and on dedicated node pools per gateway to eliminate scheduling noise and co-tenant interference from system pods like alloy and kube-state-metrics."
      ]
    },
    "body": {
      "blocks": [
        {
          "type": "text",
          "content": "This experiment deployed three Kubernetes gateway controllers — NGINX Ingress, Traefik, and Envoy Gateway — side-by-side on a single e2-standard-4 GKE node for 37 minutes. The goal: compare idle resource footprints, Gateway API maturity, configuration ergonomics, and extensibility to test the hypothesis that Envoy Gateway offers the richest feature set at the cost of higher resource consumption."
        },
        {
          "type": "callout",
          "variant": "info",
          "title": "Idle-Only Benchmark",
          "content": "All measurements reflect idle control-plane resource usage with no traffic load applied. Envoy Gateway's data-plane proxy pods (envoy-default-*) were not captured in metrics, meaning its true total footprint is undercounted. Interpret resource comparisons accordingly."
        },
        {
          "type": "topic",
          "title": "Resource Efficiency",
          "blocks": [
            {
              "type": "text",
              "content": "All three gateways are remarkably lightweight at idle, collectively consuming less than 1.5% of the node's available resources. The differences between them are small in absolute terms but reveal architectural distinctions worth understanding."
            },
            {
              "type": "row",
              "blocks": [
                {
                  "type": "metric",
                  "key": "cpu_by_pod",
                  "size": "small",
                  "insight": "Envoy Gateway's control plane consumed 56% more CPU than Traefik and 55% more than NGINX — but all three averaged under 0.002 cores."
                },
                {
                  "type": "metric",
                  "key": "memory_by_pod",
                  "size": "small",
                  "insight": "Memory follows the same pattern: Envoy Gateway at ~34 MiB, NGINX at ~29 MiB, Traefik at ~27.6 MiB. All well within minimal pod allocations."
                }
              ]
            },
            {
              "type": "comparison",
              "items": [
                {
                  "label": "Traefik",
                  "value": "2.1 core-sec / 27.6 MiB",
                  "description": "Lowest resource consumer — single Go binary combines control and data plane"
                },
                {
                  "label": "NGINX Ingress",
                  "value": "2.4 core-sec / 29.0 MiB",
                  "description": "Single-process model with embedded Lua controller keeps overhead minimal"
                },
                {
                  "label": "Envoy Gateway",
                  "value": "3.7 core-sec / 34.0 MiB",
                  "description": "Control plane only — separate data-plane proxy pods add uncaptured overhead"
                }
              ]
            },
            {
              "type": "callout",
              "variant": "warning",
              "title": "Envoy Gateway footprint is incomplete",
              "content": "The Envoy Gateway metrics only cover the controller pod. In production, envoy-default-* data-plane pods run separately and would add significant CPU and memory to the total. The true resource envelope for Envoy Gateway is materially larger than shown here."
            },
            {
              "type": "text",
              "content": "Notably, the observability stack (Alloy, kube-state-metrics, operator) consumed more resources than any individual gateway — 58% of total CPU and 47% of total memory. In production, right-sizing the monitoring footprint matters as much as gateway selection."
            },
            {
              "type": "metric",
              "key": "cpu_total",
              "size": "large",
              "insight": "Total cluster CPU: 23.3 core-seconds over 37 minutes — just 0.26% utilization of the 4-core node. The experiment node could be downsized to e2-medium for a 75% cost reduction."
            }
          ]
        },
        {
          "type": "topic",
          "title": "Gateway API Conformance",
          "blocks": [
            {
              "type": "text",
              "content": "Gateway API support is the primary differentiator among these three controllers. Their approaches range from native-first to bolted-on, which impacts configuration ergonomics and future-proofing."
            },
            {
              "type": "capabilityRow",
              "capability": "Native Gateway API implementation",
              "values": {
                "NGINX Ingress": "Add-on translation layer; not native",
                "Traefik": "Experimental provider; partial native support",
                "Envoy Gateway": "Reference implementation; fully native"
              }
            },
            {
              "type": "capabilityRow",
              "capability": "Conformance level",
              "values": {
                "NGINX Ingress": "Core (via translation); limited Extended support",
                "Traefik": "Core + some Extended; Experimental features gated",
                "Envoy Gateway": "Core + Extended; broadest Experimental coverage"
              }
            },
            {
              "type": "callout",
              "variant": "finding",
              "title": "Hypothesis partially confirmed",
              "content": "Envoy Gateway is the clear leader in Gateway API conformance as the reference implementation with the broadest Core, Extended, and Experimental coverage. However, NGINX Ingress was not the most resource-efficient — Traefik narrowly beat both NGINX and Envoy Gateway on CPU and memory, contradicting the hypothesis that NGINX's single-process model would be most efficient."
            }
          ]
        },
        {
          "type": "topic",
          "title": "Configuration Model & Extensibility",
          "blocks": [
            {
              "type": "text",
              "content": "Each gateway takes a fundamentally different approach to configuration, creating distinct trade-offs between familiarity, flexibility, and forward compatibility."
            },
            {
              "type": "table",
              "headers": [
                "Aspect",
                "NGINX Ingress",
                "Traefik",
                "Envoy Gateway"
              ],
              "rows": [
                [
                  "Primary API",
                  "Ingress + annotations",
                  "Ingress, IngressRoute CRDs, Gateway API",
                  "Gateway API exclusively"
                ],
                [
                  "Simple routing complexity",
                  "Low — familiar annotations",
                  "Low to moderate — overlapping APIs",
                  "Moderate — verbose but expressive"
                ],
                [
                  "Advanced config ergonomics",
                  "Annotation sprawl; NGINX snippets needed",
                  "Clean middleware chains via IngressRoute",
                  "Structured CRDs (BackendTrafficPolicy, SecurityPolicy)"
                ],
                [
                  "Filter / middleware architecture",
                  "Lua plugins and NGINX snippets; no formal chain",
                  "Built-in middleware chain (rate-limit, circuit-breaker, etc.)",
                  "Full Envoy filter chain (Wasm, ext_proc, Lua, ext_authz)"
                ],
                [
                  "Protocol support",
                  "TCP/UDP via ConfigMap; gRPC",
                  "TCP, UDP, gRPC natively",
                  "TCP, UDP, gRPC, HTTP/3 via Gateway API"
                ]
              ],
              "caption": "Configuration and extensibility comparison across all three gateways"
            },
            {
              "type": "text",
              "content": "Envoy Gateway's exclusive use of Gateway API means a steeper initial learning curve but avoids the configuration fragmentation that affects NGINX (annotation sprawl) and Traefik (three overlapping API surfaces). For teams already committed to Gateway API, Envoy Gateway provides the cleanest path forward."
            }
          ]
        },
        {
          "type": "topic",
          "title": "Cost & Production Readiness",
          "blocks": [
            {
              "type": "text",
              "content": "This benchmark cost $0.017 USD on a single on-demand node. Extrapolating to production reveals meaningful cost differences driven primarily by architecture rather than idle resource consumption."
            },
            {
              "type": "row",
              "blocks": [
                {
                  "type": "metric",
                  "key": "memory_total",
                  "size": "small",
                  "insight": "218 MiB total across all pods — just 1.3% of the node's 16 GB. Massive over-provisioning for a benchmark of this scale."
                },
                {
                  "type": "comparison",
                  "items": [
                    {
                      "label": "Experiment cost",
                      "value": "$0.017",
                      "description": "37 minutes on a single e2-standard-4 node"
                    },
                    {
                      "label": "Production estimate (all three)",
                      "value": "$880–$990/mo",
                      "description": "3-node HA clusters per gateway on e2-standard-4/8; Envoy Gateway requires larger nodes"
                    },
                    {
                      "label": "With 1-year CUD",
                      "value": "$554–$620/mo",
                      "description": "37% committed-use discount applied"
                    }
                  ]
                }
              ]
            },
            {
              "type": "callout",
              "variant": "warning",
              "title": "Security gaps for production",
              "content": "No NetworkPolicies, resource limits, or pod security standards were observed. All three gateways hold cluster-wide RBAC permissions. The Tailscale VPN hub pod adds a high-privilege attack vector. Before production adoption: enforce NetworkPolicy isolation, set CPU/memory limits, scope RBAC to minimum required permissions, and verify image signatures via admission control."
            },
            {
              "type": "table",
              "headers": [
                "Security Concern",
                "Impact",
                "Mitigation"
              ],
              "rows": [
                [
                  "Cluster-wide RBAC for all three gateways",
                  "Broad read access to routing config increases credential attack surface",
                  "Audit and scope ClusterRoles to minimum API groups and verbs"
                ],
                [
                  "No NetworkPolicy segmentation",
                  "Lateral movement risk between gateway, observability, and VPN pods",
                  "Enforce per-namespace NetworkPolicies restricting ingress/egress"
                ],
                [
                  "No resource limits set",
                  "Compromised pod can starve node of CPU/memory",
                  "Set requests and limits on all pods, especially in shared-node topology"
                ],
                [
                  "Mixed image provenance",
                  "NGINX (cosign partial), Traefik (no cosign), Envoy (cosign + SLSA emerging)",
                  "Pull from private registry with admission policy requiring signature verification"
                ]
              ],
              "caption": "Key security findings and recommended mitigations"
            }
          ]
        },
        {
          "type": "topic",
          "title": "Recommendations",
          "blocks": [
            {
              "type": "recommendation",
              "priority": "p0",
              "title": "Capture Envoy Gateway data-plane metrics",
              "description": "Include envoy-default-* proxy pods in metrics collection to measure Envoy Gateway's true total resource footprint. Current data only reflects the control plane, making resource comparisons incomplete.",
              "effort": "low"
            },
            {
              "type": "recommendation",
              "priority": "p0",
              "title": "Add load-generation phase",
              "description": "Introduce a traffic phase using hey or k6 with defined RPS targets to compare latency percentiles (p50/p95/p99) and throughput under realistic load. Idle-only metrics cannot differentiate proxy performance.",
              "effort": "medium"
            },
            {
              "type": "recommendation",
              "priority": "p1",
              "title": "Run Gateway API conformance test suite",
              "description": "Deploy the official gateway-api/conformance suite against each implementation to produce concrete pass/fail data for Core, Extended, and Experimental features rather than relying on documentation claims.",
              "effort": "medium"
            },
            {
              "type": "recommendation",
              "priority": "p1",
              "title": "Right-size the experiment infrastructure",
              "description": "Use e2-medium (2 vCPU, 4 GB) or spot instances for idle benchmarks — the current node is 99.7% idle on CPU. This reduces per-run cost from $0.017 to ~$0.004.",
              "effort": "low"
            },
            {
              "type": "recommendation",
              "priority": "p2",
              "title": "Separate experiment into phased time-series collection",
              "description": "Collect time-series data with distinct idle and loaded phases rather than cumulative counters from a single point in time. This enables CPU rate analysis and memory trend visualization per phase.",
              "effort": "medium"
            },
            {
              "type": "recommendation",
              "priority": "p2",
              "title": "Enforce security baselines before production evaluation",
              "description": "Add NetworkPolicies, resource limits, pod security standards, and RBAC scoping to the experiment to validate each gateway operates correctly under production-like security constraints.",
              "effort": "high"
            }
          ]
        },
        {
          "type": "text",
          "content": "Traefik emerges as the best balance of resource efficiency and configuration ergonomics for teams with straightforward routing needs — it was the lightest on both CPU and memory while offering cleaner advanced configuration than NGINX's annotation model. Envoy Gateway is the right choice for teams investing in Gateway API as their long-term standard and needing deep extensibility through Envoy's filter chain, but its two-process architecture and incomplete metrics capture mean the true resource cost remains to be quantified. NGINX Ingress occupies a middle ground: familiar and battle-tested, but its annotation-driven model is showing its age against structured CRD-based alternatives. A load-tested follow-up experiment with complete Envoy data-plane metrics is essential before making a production decision."
        }
      ]
    },
    "summary": "Analysis incomplete",
    "generatedAt": "2026-02-12T20:13:58Z",
    "model": "claude-opus-4-6"
  }
}
